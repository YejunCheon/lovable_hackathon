
from app.adapters import gemini, pgvector, pg
from app.utils import scoring, mmr
import logging

logger = logging.getLogger(__name__)

async def hybrid_retrieve(persona: dict, use_vector_search: bool = False) -> list[dict]:
    """
    NEW APPROACH: Structured SQL search using LLM-generated WHERE conditions.
    
    Instead of vector/keyword search, uses field-specific filters generated by LLM
    to directly query the database with precise WHERE clauses.
    
    Args:
        persona: Persona dictionary containing search_filters
        use_vector_search: If True, also perform vector search and blend (legacy mode)
    """
    logger.info("=" * 60)
    logger.info("2Ô∏è‚É£ Structured Search ÏãúÏûë (LLM ÏÉùÏÑ± SQL Ï°∞Í±¥)")
    logger.info("=" * 60)
    
    persona_data = persona.get("persona", {})
    search_filters = persona_data.get("search_filters", {})
    
    if not search_filters:
        logger.warning("‚ö†Ô∏è  No search_filters found in persona, falling back to legacy search")
        # Fallback to old method if search_filters not available
        return await _legacy_hybrid_retrieve(persona, use_vector_search)
    
    # Convert Pydantic model to dict if needed
    if hasattr(search_filters, 'model_dump'):
        search_filters = search_filters.model_dump()
    
    # Remove None values
    search_filters = {k: v for k, v in search_filters.items() if v is not None}
    
    if not search_filters:
        logger.warning("‚ö†Ô∏è  search_filters is empty, returning empty results")
        return []
    
    logger.info("üîç [Step 1] Structured SQL Search Ïã§Ìñâ Ï§ë...")
    logger.info(f"   ‚Üí Filters: {list(search_filters.keys())}")
    
    try:
        # Use structured_search with LLM-generated filters
        results = await pg.structured_search(search_filters, k=30)
        logger.info(f"   ‚úÖ Structured search ÏôÑÎ£å: {len(results)}Í∞ú Í≤∞Í≥º")
        
        if results:
            top_scores = [f"{r.get('score', 0):.4f}" for r in results[:3]]
            logger.info(f"   üìä ÏÉÅÏúÑ 3Í∞ú Ï†êÏàò: {top_scores}")
        
        # Optional: Apply vector search for additional relevance
        if use_vector_search and len(results) > 0:
            logger.info("üîç [Step 2] Vector Search Î≥¥Ï°∞ Ïã§Ìñâ Ï§ë...")
            query_text = persona_data.get("query_text", "")
            if query_text:
                try:
                    query_vector = await gemini.embed_query(query_text)
                    vec_results = await pgvector.vector_topk(query_vector, k=20)
                    
                    if vec_results:
                        logger.info(f"   ‚úÖ Vector search Î≥¥Ï°∞ Í≤∞Í≥º: {len(vec_results)}Í∞ú")
                        # Blend with structured results using RRF
                        blended = scoring.rrf_fusion(results, vec_results, k=60)
                        results = blended
                        logger.info(f"   ‚úÖ RRF Blended ÏôÑÎ£å: {len(results)}Í∞ú")
                except Exception as e:
                    logger.warning(f"   ‚ö†Ô∏è  Vector search Ïã§Ìå®, structured resultsÎßå ÏÇ¨Ïö©: {e}")
        
        logger.info("=" * 60)
        return results[:12]  # Return top 12
        
    except Exception as e:
        logger.error(f"   ‚ùå Structured search Ïã§Ìå®: {e}", exc_info=True)
        return []


async def _legacy_hybrid_retrieve(persona: dict, use_vector_search: bool = True) -> list[dict]:
    """
    Legacy hybrid retrieval method (kept for backward compatibility).
    """
    logger.info("‚ö†Ô∏è  Using legacy hybrid retrieval")
    # ... (keep old implementation as fallback)
    return []
